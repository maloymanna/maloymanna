<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Spark on Maloy Manna</title>
    <link>https://maloymanna.github.io/tags/spark/</link>
    <description>Recent content in Spark on Maloy Manna</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2007 - 2025. All rights reserved.</copyright>
    <lastBuildDate>Wed, 18 Nov 2015 11:37:49 +0000</lastBuildDate>
    <atom:link href="https://maloymanna.github.io/tags/spark/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Data processing with Spark in R &amp; Python</title>
      <link>https://maloymanna.github.io/2015/11/18/data-processing-with-spark-in-r-python/</link>
      <pubDate>Wed, 18 Nov 2015 11:37:49 +0000</pubDate>
      <guid>https://maloymanna.github.io/2015/11/18/data-processing-with-spark-in-r-python/</guid>
      <description>&lt;p&gt;I recently gave a talk on data processing with Apache Spark using R and Python. tl;dr - the slides and presentation can be accessed below (free registration):&lt;/p&gt;&#xA;&lt;div class=&#34;slideshare-embed&#34;&gt;&#xA;    &lt;iframe src=&#34;https://www.slideshare.net/slideshow/embed_code/key/5nBaQvLpL3zIHt&#34; &#xA;            width=&#34;595&#34; &#xA;            height=&#34;485&#34; &#xA;            frameborder=&#34;0&#34; &#xA;            marginwidth=&#34;0&#34; &#xA;            marginheight=&#34;0&#34; &#xA;            scrolling=&#34;no&#34; &#xA;            style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; &#xA;            allowfullscreen&gt;&#xA;    &lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;As noted in my previous &lt;a href=&#34;https://biguru.wordpress.com/2015/03/23/spark-big-data-platform-future/&#34;&gt;post&lt;/a&gt;, Spark has become the defacto standard for big data applications and has been adopted quickly by the industry. See Cloudera&amp;rsquo;s  &lt;a href=&#34;https://vision.cloudera.com/one-platform/&#34;&gt;One Platform&lt;/a&gt; initiative blog post by CEO Mike Olson for their commitment to Spark.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Set up a Hadoop Spark cluster in 10 minutes with Vagrant</title>
      <link>https://maloymanna.github.io/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</link>
      <pubDate>Tue, 30 Dec 2014 22:36:53 +0000</pubDate>
      <guid>https://maloymanna.github.io/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</guid>
      <description>&lt;p&gt;With each of the big 3 Hadoop vendors - &lt;strong&gt;Cloudera&lt;/strong&gt;, &lt;strong&gt;Hortonworks&lt;/strong&gt; and &lt;strong&gt;MapR&lt;/strong&gt; each providing their own Hadoop &lt;span style=&#34;color: blue;&#34;&gt;sandbox&lt;/span&gt; &lt;strong&gt;virtual machines&lt;/strong&gt; (VMs), trying out Hadoop today has become extremely easy. For a developer, it is extremely useful to download a get started with one of these VMs and try out Hadoop to practice data science right away.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://maloymanna.github.io/post/vagrant-hadoop-spark-cluster.png?w=300&#34; alt=&#34;Vagrant Hadoop Spark Cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;However, with the core &lt;a href=&#34;hadoop.apache.org/&#34;&gt;Apache Hadoop&lt;/a&gt;, these vendors package their own software into their distributions, mostly for the orchestration and management, which can be a pain due to the multiple scattered open-source projects within the Hadoop ecosystem. e.g. Hortonworks includes the open-source &lt;strong&gt;Ambari&lt;/strong&gt; while Cloudera includes its own &lt;strong&gt;Cloudera Manager&lt;/strong&gt; for orchestrating Hadoop installations and managing multi-node clusters.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of Big Data – Part 2 - Hadoop</title>
      <link>https://maloymanna.github.io/2014/04/13/basics-of-big-data-part-2-hadoop/</link>
      <pubDate>Sun, 13 Apr 2014 18:12:16 +0000</pubDate>
      <guid>https://maloymanna.github.io/2014/04/13/basics-of-big-data-part-2-hadoop/</guid>
      <description>&lt;p&gt;As discussed in &lt;a href=&#34;http://biguru.wordpress.com/2013/08/21/basics-of-big-data-part-1/&#34;&gt;Part 1&lt;/a&gt; of this series, &lt;strong&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/strong&gt; is the foremost among tools being currently used for deriving value out of Big Data. The process of gaining insights from data through Business Intelligence and analytics essentially remains the same. However, with the huge variety, volume and velocity (the 3Vs of Big Data), it’s become necessary to re-think of the data management infrastructure. Hadoop, originally designed to be used with the MapReduce algorithm to solve parallel processing constraints in distributed architectures (e.g. web indexing) of web giants like Yahoo or Google, has become the de-facto standard for Big Data (large-scale data-intensive) analytics platforms.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
