<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Hadoop on Maloy Manna</title>
    <link>https://maloymanna.github.io/tags/hadoop/</link>
    <description>Recent content in Hadoop on Maloy Manna</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2007 - 2025. All rights reserved.</copyright>
    <lastBuildDate>Fri, 14 Jul 2017 11:27:09 +0000</lastBuildDate>
    <atom:link href="https://maloymanna.github.io/tags/hadoop/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>9 features of modern data architectures</title>
      <link>https://maloymanna.github.io/2017/07/14/9-features-of-modern-data-architectures/</link>
      <pubDate>Fri, 14 Jul 2017 11:27:09 +0000</pubDate>
      <guid>https://maloymanna.github.io/2017/07/14/9-features-of-modern-data-architectures/</guid>
      <description>&lt;p&gt;The last few years has seen a massive change in the data landscape. With the rise of big data, there&amp;rsquo;s been rapid innovation in the tools, skills and roles working on data systems. Data architectures have evolved beyond monolithic, centralized databases and unwieldy analytic applications to distributed, scalable architectures with simpler collaborative and interactive analytic tools. In this post, I look at the defining features of modern data architectures.&lt;/p&gt;&#xA;&lt;p&gt;Modern data architectures generally feature the following (though not all of these may be present in the same system):&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hadoop&#39;s small files problem</title>
      <link>https://maloymanna.github.io/2016/02/16/hadoop-small-files-problem/</link>
      <pubDate>Tue, 16 Feb 2016 08:09:12 +0000</pubDate>
      <guid>https://maloymanna.github.io/2016/02/16/hadoop-small-files-problem/</guid>
      <description>&lt;p&gt;Small files are a big problem in Hadoop.&lt;/p&gt;&#xA;&lt;p&gt;Hadoop is designed to manage big data and by design this means HDFS is designed to store very large files in a distributed cluster with streaming access to this data. For reference, a typical block in HDFS is 64 MB or 128 MB. Each small file (few MB or less) is stored in a block and multiple small files could be stored in blocks across different nodes of the distributed cluster.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data processing with Spark in R &amp; Python</title>
      <link>https://maloymanna.github.io/2015/11/18/data-processing-with-spark-in-r-python/</link>
      <pubDate>Wed, 18 Nov 2015 11:37:49 +0000</pubDate>
      <guid>https://maloymanna.github.io/2015/11/18/data-processing-with-spark-in-r-python/</guid>
      <description>&lt;p&gt;I recently gave a talk on data processing with Apache Spark using R and Python. tl;dr - the slides and presentation can be accessed below (free registration):&lt;/p&gt;&#xA;&lt;div class=&#34;slideshare-embed&#34;&gt;&#xA;    &lt;iframe src=&#34;https://www.slideshare.net/slideshow/embed_code/key/5nBaQvLpL3zIHt&#34; &#xA;            width=&#34;595&#34; &#xA;            height=&#34;485&#34; &#xA;            frameborder=&#34;0&#34; &#xA;            marginwidth=&#34;0&#34; &#xA;            marginheight=&#34;0&#34; &#xA;            scrolling=&#34;no&#34; &#xA;            style=&#34;border:1px solid #CCC; border-width:1px; margin-bottom:5px; max-width: 100%;&#34; &#xA;            allowfullscreen&gt;&#xA;    &lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&lt;p&gt;As noted in my previous &lt;a href=&#34;https://biguru.wordpress.com/2015/03/23/spark-big-data-platform-future/&#34;&gt;post&lt;/a&gt;, Spark has become the defacto standard for big data applications and has been adopted quickly by the industry. See Cloudera&amp;rsquo;s  &lt;a href=&#34;https://vision.cloudera.com/one-platform/&#34;&gt;One Platform&lt;/a&gt; initiative blog post by CEO Mike Olson for their commitment to Spark.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why Spark is the big data platform of the future</title>
      <link>https://maloymanna.github.io/2015/03/23/spark-big-data-platform-future/</link>
      <pubDate>Mon, 23 Mar 2015 12:03:35 +0000</pubDate>
      <guid>https://maloymanna.github.io/2015/03/23/spark-big-data-platform-future/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Apache Spark&lt;/strong&gt; has created a lot of buzz recently. In fact, beyond the buzz, Apache Spark has seen phenomenal adoption and has been marked out as the successor to Hadoop MapReduce.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://maloymanna.github.io/post/apache-spark.jpg?w=300&#34; alt=&#34;Apache Spark&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Google Trends confirms the &lt;strong&gt;hockey stick like growth&lt;/strong&gt; in interest in Apache Spark.  All leading Hadoop vendors, including Cloudera, now include Apache Spark in their Hadoop distribution.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://maloymanna.github.io/post/googletrends.jpg?w=300&#34; alt=&#34;GoogleTrends - Apache Spark&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;So what exactly is Spark, and why has it generated such enthusiasm? Apache Spark is an open-source big data processing framework designed for speed and ease of use.  Spark is well-known for its in-memory performance, but that has also given rise to misconceptions about its on-disk abilities. Spark is in fact a general execution engine - which has a greatly improved performance both in-memory as well as on-disk, when compared with older frameworks like MapReduce. With its advanced &lt;strong&gt;DAG&lt;/strong&gt; (directed acyclic graph) execution engine, Spark can run programs up to &lt;strong&gt;100x faster than MapReduce in memory, or 10x faster on-disk.&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Set up a Hadoop Spark cluster in 10 minutes with Vagrant</title>
      <link>https://maloymanna.github.io/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</link>
      <pubDate>Tue, 30 Dec 2014 22:36:53 +0000</pubDate>
      <guid>https://maloymanna.github.io/2014/12/30/set-up-a-hadoop-spark-cluster-in-10-minutes-with-vagrant/</guid>
      <description>&lt;p&gt;With each of the big 3 Hadoop vendors - &lt;strong&gt;Cloudera&lt;/strong&gt;, &lt;strong&gt;Hortonworks&lt;/strong&gt; and &lt;strong&gt;MapR&lt;/strong&gt; each providing their own Hadoop &lt;span style=&#34;color: blue;&#34;&gt;sandbox&lt;/span&gt; &lt;strong&gt;virtual machines&lt;/strong&gt; (VMs), trying out Hadoop today has become extremely easy. For a developer, it is extremely useful to download a get started with one of these VMs and try out Hadoop to practice data science right away.&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://maloymanna.github.io/post/vagrant-hadoop-spark-cluster.png?w=300&#34; alt=&#34;Vagrant Hadoop Spark Cluster&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;However, with the core &lt;a href=&#34;hadoop.apache.org/&#34;&gt;Apache Hadoop&lt;/a&gt;, these vendors package their own software into their distributions, mostly for the orchestration and management, which can be a pain due to the multiple scattered open-source projects within the Hadoop ecosystem. e.g. Hortonworks includes the open-source &lt;strong&gt;Ambari&lt;/strong&gt; while Cloudera includes its own &lt;strong&gt;Cloudera Manager&lt;/strong&gt; for orchestrating Hadoop installations and managing multi-node clusters.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of Big Data - Building a Hadoop data warehouse</title>
      <link>https://maloymanna.github.io/2014/05/12/basics-of-big-data-building-a-hadoop-data-warehouse/</link>
      <pubDate>Mon, 12 May 2014 12:55:24 +0000</pubDate>
      <guid>https://maloymanna.github.io/2014/05/12/basics-of-big-data-building-a-hadoop-data-warehouse/</guid>
      <description>&lt;p&gt;This is the 3rd part of a series of posts on Big Data. Read &lt;a href=&#34;http://biguru.wordpress.com/2013/08/21/basics-of-big-data-part-1/&#34;&gt;Part-1&lt;/a&gt; (What is Big Data) and &lt;a href=&#34;http://biguru.wordpress.com/2014/04/13/basics-of-big-data-part-2-hadoop/&#34;&gt;Part-2 (Hadoop)&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Traditionally data warehouses have been built with relational databases as backbone. With the new challenges (&lt;a href=&#34;http://biguru.wordpress.com/2013/08/21/basics-of-big-data-part-1/&#34;&gt;3Vs&lt;/a&gt;) of Big Data, relational databases have been falling short of the requirements of handling&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;New data types (unstructured data)&lt;/li&gt;&#xA;&lt;li&gt;Extended analytic processing&lt;/li&gt;&#xA;&lt;li&gt;Throughput (TB/hour loading) with immediate query access&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;The industry has turned to Hadoop as a disruptive solution for these very challenges.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of Big Data – Part 2 - Hadoop</title>
      <link>https://maloymanna.github.io/2014/04/13/basics-of-big-data-part-2-hadoop/</link>
      <pubDate>Sun, 13 Apr 2014 18:12:16 +0000</pubDate>
      <guid>https://maloymanna.github.io/2014/04/13/basics-of-big-data-part-2-hadoop/</guid>
      <description>&lt;p&gt;As discussed in &lt;a href=&#34;http://biguru.wordpress.com/2013/08/21/basics-of-big-data-part-1/&#34;&gt;Part 1&lt;/a&gt; of this series, &lt;strong&gt;&lt;em&gt;Hadoop&lt;/em&gt;&lt;/strong&gt; is the foremost among tools being currently used for deriving value out of Big Data. The process of gaining insights from data through Business Intelligence and analytics essentially remains the same. However, with the huge variety, volume and velocity (the 3Vs of Big Data), it’s become necessary to re-think of the data management infrastructure. Hadoop, originally designed to be used with the MapReduce algorithm to solve parallel processing constraints in distributed architectures (e.g. web indexing) of web giants like Yahoo or Google, has become the de-facto standard for Big Data (large-scale data-intensive) analytics platforms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of Big Data - Part 1</title>
      <link>https://maloymanna.github.io/2013/08/21/basics-of-big-data-part-1/</link>
      <pubDate>Wed, 21 Aug 2013 23:02:49 +0000</pubDate>
      <guid>https://maloymanna.github.io/2013/08/21/basics-of-big-data-part-1/</guid>
      <description>&lt;p&gt;You can’t miss all the buzz about &lt;strong&gt;Big Data&lt;/strong&gt;! Over the past few years, the buzz around the cloud and &lt;strong&gt;Big Data&lt;/strong&gt; shaping most of the future of computing, IT and analytics in particular has grown incessantly strong. As with most buzz words, which are then hijacked by marketing to suit their own products’ storylines, but which nonetheless manage to confuse users in business and staff in IT as well, &lt;strong&gt;Big Data&lt;/strong&gt; means several things to several people.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Review of the BT Summit – Cloud computing, SOA and BI tracks</title>
      <link>https://maloymanna.github.io/2009/11/13/review-of-the-bt-summit--cloud-computing-soa-and-bi-tracks/</link>
      <pubDate>Fri, 13 Nov 2009 08:12:30 +0000</pubDate>
      <guid>https://maloymanna.github.io/2009/11/13/review-of-the-bt-summit--cloud-computing-soa-and-bi-tracks/</guid>
      <description>&lt;p&gt;I attended the &lt;a href=&#34;http://www.btmarch.com/btsummit/&#34;&gt;Business Technology Summit in Bangalore&lt;/a&gt; last week – 3rd and 4th November. There were 3 tracks on cloud computing, Service Oriented Architecture and Business Intelligence, and I chose a mix of sessions across each.&lt;/p&gt;&#xA;&lt;p&gt;**Overall impression:**The BT Summit was heavily focused on cloud computing with half of second day having a deep dive into Amazon’s EC2 cloud offering, and several keynotes. SOA and web services, REST and similar architectural sessions were interspersed but definitely not a first-class citizen. BI came a poor third with a poor choice of sessions, and more of a rehash of what is out there for everyone, rather than something on the cutting-edge including use of appliances and columnar databases, as also in-memory databases and use of Flash and AJAX for interactive BI front-ends.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
